<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">12307702</article-id><article-id pub-id-type="pmid">40730596</article-id>
<article-id pub-id-type="publisher-id">8778</article-id><article-id pub-id-type="doi">10.1038/s41598-025-08778-6</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Comparing non-machine learning vs. machine learning methods for Ki67 scoring in gastrointestinal neuroendocrine tumors</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4644-7919</contrib-id><name><surname>Mola</surname><given-names>Nazanin</given-names></name><address><email>Nazanin.mola@ihelse.net</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Weishaupt</surname><given-names>Hrafn</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Krasontovitsch</surname><given-names>Valentin</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Hodneland</surname><given-names>Erlend</given-names></name><xref ref-type="aff" rid="Aff4">4</xref><xref ref-type="aff" rid="Aff5">5</xref><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Leh</surname><given-names>Sabine</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03np4e098</institution-id><institution-id institution-id-type="GRID">grid.412008.f</institution-id><institution-id institution-id-type="ISNI">0000 0000 9753 1393</institution-id><institution>Department of Pathology, </institution><institution>Haukeland University Hospital, </institution></institution-wrap>Post Office Box 1400, 5021 Bergen, Norway </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03zga2b32</institution-id><institution-id institution-id-type="GRID">grid.7914.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7443</institution-id><institution>Department of Clinical Medicine, Faculty of Medicine, </institution><institution>University of Bergen, </institution></institution-wrap>Bergen, Norway </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03np4e098</institution-id><institution-id institution-id-type="GRID">grid.412008.f</institution-id><institution-id institution-id-type="ISNI">0000 0000 9753 1393</institution-id><institution>Department of Medical Genetics, </institution><institution>Haukeland University Hospital, </institution></institution-wrap>Bergen, Norway </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03zga2b32</institution-id><institution-id institution-id-type="GRID">grid.7914.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7443</institution-id><institution>Department of Mathematics, </institution><institution>University of Bergen, </institution></institution-wrap>Bergen, Norway </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03np4e098</institution-id><institution-id institution-id-type="GRID">grid.412008.f</institution-id><institution-id institution-id-type="ISNI">0000 0000 9753 1393</institution-id><institution>Department of Research and Development, </institution><institution>Haukeland University Hospital, </institution></institution-wrap>Bergen, Norway </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03np4e098</institution-id><institution-id institution-id-type="GRID">grid.412008.f</institution-id><institution-id institution-id-type="ISNI">0000 0000 9753 1393</institution-id><institution>Mohn Medical Imaging and Visualization Centre, </institution><institution>Haukeland University Hospital, </institution></institution-wrap>Bergen, Norway </aff></contrib-group><pub-date pub-type="epub"><day>29</day><month>7</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>29</day><month>7</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>15</volume><elocation-id>27700</elocation-id><history><date date-type="received"><day>3</day><month>10</month><year>2024</year></date><date date-type="accepted"><day>23</day><month>6</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">The Ki67 score is a crucial prognostic biomarker for neuroendocrine tumors, but its manual assessment is labor-intensive, requiring the counting of 500-2,000 cells in hotspots. Digital image analysis could streamline this process, yet few comprehensive comparisons exist between different tools. We compared a non-machine learning (non-ML) tool (ImageScope, Leica Biosystems) with a machine learning (ML) tool (Aiforia Create, Aiforia Technologies) on Ki67-stained slides from 10 low proliferative neuroendocrine tumor cases (Ki67 score&#x02009;&#x0003c;&#x02009;5%, eight regions per slide). Performance metrics based on the coordinates of detected cells were used to assess the capability of image analysis tools to detect (i) total and (ii) Ki67 positive tumor cells, and consequently calculate the (iii) Ki67 score. Manual scoring by an experienced pathologist was used as the reference standard. The ML compared to the non-ML tool showed better performance metrics (F-score 0.90 vs. 0.74) in detecting the tumor cells. Also, the ML tool had a higher agreement with the reference standard in detecting tumor cells (ICC 0.91 vs. 0.62), Ki67 positive tumor cells (ICC 0.70 vs. 0.24), and the Ki67 score (ICC 0.86 vs. 0.45). Our findings highlight the enhanced accuracy of ML-based image analysis in detecting the correct tumor cells, outperforming traditional methods.</p><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1038/s41598-025-08778-6.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Ki67</kwd><kwd>Neuroendocrine tumor (NET)</kwd><kwd>Image analysis</kwd><kwd>Immunohistochemistry</kwd><kwd>Intra-observer agreement</kwd><kwd>Machine learning</kwd></kwd-group><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Image processing</kwd><kwd>Cellular imaging</kwd><kwd>Medical imaging</kwd><kwd>Machine learning</kwd></kwd-group><funding-group><award-group><funding-source><institution>University of Bergen (incl Haukeland University Hospital)</institution></funding-source></award-group><open-access><p>Open access funding provided by University of Bergen.</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par7">Neuroendocrine neoplasms are a rare and heterogeneous group of neoplasms originating from neuroendocrine cells. These neoplasms often show a characteristic morphology and express general markers of neuroendocrine differentiation, such as synaptophysin and chromogranin. Biological behavior and response to therapy are dependent on the site of origin, grade of differentiation, and proliferation rate. In particular, proliferation is a critical factor for the prognosis of well-differentiated neuroendocrine neoplasms originating from the digestive tract, known as neuroendocrine tumors (NETs), as differentiation alone does not provide prognostic information<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Consequently, the WHO&#x02019;s classification of NETs in the digestive tract is based on the proliferation rate.</p><p id="Par8">NETs are divided into three grades: G1 or low grade (mitoses&#x02009;&#x0003c;&#x02009;2 in 2 mm<sup>2</sup>or Ki67 score&#x02009;&#x0003c;&#x02009;3% [0&#x02013;2.99%]); G2 or intermediate grade (mitoses of 2 to 20 in 2 mm<sup>2</sup>or Ki67 score 3&#x02013;20%); and G3 or high grade (mitoses of &#x0003e;&#x02009;20 in 2 mm<sup>2</sup>or Ki67 score&#x02009;&#x0003e;&#x02009;20%).</p><p id="Par9">Given the crucial role of accurate tumor grading in prognosis and treatment planning, particularly for distinguishing G1 from G2 NETs that have distinct clinical outcomes, it is essential to rely on robust markers for grading. Proliferation itself can be measured by the mitosis count or Ki67 score, where the latter proved to be a better indicator of biological behavior<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. The reliability of the Ki67 score increases with the size of the evaluated area, as a larger area provides a greater number of positively and negatively stained cells, resulting in a more statistically accurate reflection of the proliferation rate in the whole slide<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. However, manual cell counting is a time-consuming task, and its application in a large area is impractical in routine diagnostics. As a compromise between time efficiency and reliability of the estimated Ki67 score, counting a minimum of 500-2,000 tumor cells is recommended<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR6">6</xref></sup>. Basing the measurement on a large number of cells is especially crucial for low proliferative tumors, in which counting only a limited number of tumor cells can easily lead to incorrect results<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. Despite this, due to increased workload<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> pathologists often opt for eyeballing, which in turn suffers from lack of reproducibility, precision, and accuracy and is further affected by inter-observer variability<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup>. Furthermore, a correct estimation of the Ki67 score relies on familiarity with histopathological subtleties of a given tumor. For instance, the presence of intra-tumoral lymphocytes or heavily inflamed tumor stroma may result in overestimation of the Ki67 score<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. Therefore, there is a need for an unbiased, fast, and reliable analytical method for Ki67 score estimation.</p><p id="Par10">The advent of digital pathology has enabled a wide variety of computational methods to extract data from digitized tissue slides<sup><xref ref-type="bibr" rid="CR13">13</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref></sup>. Digital image analysis can be a reproducible<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and faster alternative to manual scoring of Ki67. Several studies have reported on the automated estimation of the Ki67 score in different malignancies, like breast<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>lung<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>colorectal carcinoma<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>and NETs<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. However, the application of digital pathology still faces challenges, such as (i) distinguishing tumor from non-tumor cells, (ii) proper cell segmentation (dealing with overlapping tumor cells and inhomogeneous staining), and (iii) discerning Ki67 positive from negative tumor cells (with respect to choosing a threshold for positivity).</p><p id="Par11">While several studies have already investigated possible solutions for the above-mentioned challenges<sup><xref ref-type="bibr" rid="CR19">19</xref>&#x02013;<xref ref-type="bibr" rid="CR21">21</xref></sup> there is a limited number of comprehensive efforts comparing the performance between different tools<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. Furthermore, existing investigations do not assess performance at the individual cell level. For instance, one study<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> has performed pixel-level evaluation of AI predictions or correlated the total number of detected nuclei with manual counts, without verifying whether the same individual cells were correctly identified. This gap is critical because simply relying on the final number of detected cells or the calculated Ki67 score can lead to overlooking inaccuracies in identifying the correct cells. Assessing performance at the cell level ensures that the image analysis tools detect the correct cells, rather than achieving seemingly accurate counts despite incorrect detections.</p><p id="Par12">The contribution of the current study is to address this specific gap by evaluating two image analysis tools: a commercially available non-machine learning (non-ML)-based image analysis software and a ML-based image analysis platform for calculating the Ki67 score in NETs. The performance of the employed tools was assessed by comparing not only the calculated Ki67 scores and the number of detected (total and Ki67 positive) tumor cells, but also by measuring the spatial distance between the tumor cells identified by the image analysis tools and those annotated by a gastrointestinal pathologist (SL) aiming to determine whether the correct cells were identified.</p></sec><sec id="Sec2"><title>Materials and methods</title><sec id="Sec7"><title>Biopsies</title><p id="Par14">Biopsy cases (<italic>n</italic>&#x02009;=&#x02009;39) from gastrointestinal neuroendocrine tumors were collected from the year 2015 to 2017, from the archives of the Department of Pathology at Haukeland University Hospital, Bergen, Norway. The cases consisted of both endoscopic biopsies and resection specimens. To enable a thorough comparison of the performance of the image analysis tools, a broad variety of NETs in terms of location, stromal content and inflammation were chosen. All cases were reported to have a low Ki67 score of less than 5% (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). The original diagnostic slides (Superfrost plus glass) were used, with the biopsy sections having been cut at a thickness of 5 microns (&#x000b5;m) and stained with Ki67 (Clone MIB-1, Dako, M7240) on the Roche Ventana Benchmark (Roche Diagnostics, Rotkreuz, Switzerland). The glass slides were scanned with a Hamamatsu Nanozoomer XR (Hamamatsu Photonics Norden AB, Kista, Sweden) at 40x magnification, resulting in a resolution of 0.23&#x000a0;&#x003bc;m per pixel. Digital slides were accessed through Aperio eSlide Manager 12 (W10-7018) and viewed in Aperio ImageScope (v12.4.0.7018, Aperio ImageScope, Leica Biosystems, IL, US). All materials were acquired, and all methods were carried out in accordance with relevant guidelines and regulations.</p><p>
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Grading and localization of the neuroendocrine tumors in the training and test dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2" colspan="2">Total number of samples</th><th align="left">Training</th><th align="left">Test</th></tr><tr><th align="left">29</th><th align="left">10</th></tr></thead><tbody><tr><td align="left" rowspan="2">Grading</td><td align="left">G1</td><td align="left">25</td><td align="left">8</td></tr><tr><td align="left">G2</td><td align="left">4</td><td align="left">2</td></tr><tr><td align="left" rowspan="6">Localization</td><td align="left">Small intestine</td><td align="left">10</td><td align="left">5</td></tr><tr><td align="left">Colon</td><td align="left">&#x02013;</td><td align="left">1</td></tr><tr><td align="left">Appendix</td><td align="left">14</td><td align="left">2</td></tr><tr><td align="left">Rectum</td><td align="left">2</td><td align="left">1</td></tr><tr><td align="left">Stomach</td><td align="left">2</td><td align="left">1</td></tr><tr><td align="left">Pancreas</td><td align="left">1</td><td align="left">-</td></tr></tbody></table><table-wrap-foot><p>The grading is that of the original pathology reports. The G2 samples had a Ki67 score of less than 5%.</p></table-wrap-foot></table-wrap>
</p></sec><sec id="Sec8"><title>Training and test datasets</title><p id="Par17">The cases were randomly split into a training/validation dataset (<italic>n</italic>&#x02009;=&#x02009;29, male/female&#x02009;=&#x02009;13/16, mean age&#x02009;=&#x02009;56.9) and a test dataset (<italic>n</italic>&#x02009;=&#x02009;10, male/female&#x02009;=&#x02009;6/4, mean age&#x02009;=&#x02009;63.3). For the training/validation dataset, the whole slide images (<italic>n</italic>&#x02009;=&#x02009;29) were uploaded to an ML platform, and different regions representing the normal histological variation of each case were used for training and validation. For testing, eight identically sized regions of interest (ROIs) were selected for each case (<italic>n</italic>&#x02009;=&#x02009;10) by the first author (MSc in biomedicine) under the supervision of an experienced gastrointestinal pathologist (SL). Each test ROI marked a square region with an edge length of 200&#x000a0;&#x003bc;m in the area with the highest number of positively Ki67-stained tumor cells. Approximately 200 cells were contained within each test ROI. For the test dataset, only the ROIs were uploaded to the ML platform. Ki67 scores were calculated for each ROI by dividing the number of positive tumor cells by the number of tumor cells. The overall score for the given slide was determined by summing all the positive and tumor cell counts across the eight ROIs.</p></sec><sec id="Sec9"><title>Manual Ki67 score assessment (reference standard)</title><p id="Par19">The ROIs from the test dataset were exported from ImageScope as .tiff files. Manual annotation was conducted by an experienced gastrointestinal pathologist (SL) on Ki67-stained sections using the dot annotation feature of ImageJ<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> with the multi-point tool. The results of the annotation process included the number of marked cells on the image and the coordinates of these dot markings. The pathologist (SL) manually counted tumor cells within the ROIs twice, with a wash out period of six months between the counts. Illustrative examples and an instruction to dismiss faintly stained tumor cells were provided for the sake of consistency in the annotations. The intra-observer variability between the two counting rounds was found to be minimal (Supplementary Fig. <xref rid="MOESM1" ref-type="media">S1</xref>). The second count was considered the reference standard for all comparison with the image analysis tools (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>a).</p><p id="Par20">
<fig id="Fig1"><label>Fig. 1</label><caption><p>Tumor cell nuclei detection. (<bold>a</bold>) One ROI with the reference standard; black and yellow squares respectively mark all and positive tumor cells. (<bold>b</bold>) Mark-up image resulting from non-machine learning based image analysis with ImageScope; blue and red markings respectively highlight detected Ki67 negative and positive tumor cells. (<bold>c</bold>) Mark-up image resulting from machine learning based image analysis with Aiforia; highlighted red area is the detected tumor region, red and green circles respectively show detected Ki67 negative and positive tumor cells.</p></caption><graphic xlink:href="41598_2025_8778_Fig1_HTML" id="d33e509"/></fig>
</p></sec><sec id="Sec10"><title>Non-ML based image analysis with Aperio ImageScope</title><p id="Par22">The Nuclear v9 algorithm (Aperio ImageScope)<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> was used for the automatic detection of total and Ki67 positive tumor cells (nuclei). This algorithm was chosen as it represents a conventional image analysis tool commonly used in research, with a user-friendly interface. Annotations and analyses were performed by the first author (MSc in biomedicine) under the supervision of an experienced gastrointestinal pathologist (SL). Several representative regions in the training/validation dataset were employed to adjust the input parameters to improve the detection and segmentation of tumor cells. The best parameter set (Supplementary Table <xref rid="MOESM1" ref-type="media">S1</xref>), out of the evaluated configurations, was then applied to analyze the test dataset. Analysis produced mark-up images that classified and color-coded the detected cells on the basis of their staining intensity. Blue and red highlighting were used for negatively and positively Ki67-stained cells, respectively (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>b).</p><p id="Par23">Since the algorithm did not return any spatial information for the detected cells, we exported the mark-up images into ImageJ and manually annotated the detected cells to obtain their coordinates for later assignment and comparison.</p></sec><sec id="Sec11"><title>ML based image analysis with Aiforia</title><p id="Par25">A convolutional neural network was established on Aiforia (Aiforia Technologies Oyj, Helsinki, Finland), a cloud-based ML platform. The use of this ML-based platform was chosen to leverage state-of-the-art technology. It also offers excellent customer support and a user-friendly interface, making it easy to experiment with and implement the ML analysis. For our study, the convolutional neural network consisted of two neural networks. The first neural network segmented tumor areas, and the second network detected Ki67 positive and negative tumor cells within the segmented tumor areas (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>c). Annotations and analyses, in here also, were performed by the first author (MSc in biomedicine) under the supervision of an experienced gastrointestinal pathologist (SL). The output included the number of detected tumor cells and their center coordinates. The training/validation dataset (<italic>n</italic>&#x02009;=&#x02009;29) included 6&#x02005;072 manually annotated tumor areas and 13&#x02005;030 labeled Ki67 positive/negative tumor cells for training. The AI model was trained from scratch and initialized with random values. The mini batch size was 20 by default and no cross-validation was used. The training dataset was digitally augmented using random scaling of &#x02212;&#x000a0;20 to 20%, 0 to 10% aspect ratio change, 0 to 10% shear angle, &#x02212; 20 to 20% brightness and &#x02212;&#x02009;10 to 10% contrast change, 0&#x02013;1% white balance change, and flipping both vertically and horizontally (Supplementary Table <xref rid="MOESM2" ref-type="media">S2</xref>). The number of training iterations was set to 30,000. The fine-tuning of hyperparameters was conducted in collaboration with Aiforia&#x02019;s specialists, leveraging their expertise to optimize the model for accuracy and efficiency. The performance of our trained model was evaluated on previously unseen regions from the training/validation dataset and further tested on the independent test dataset, using statistical measures including precision, sensitivity, and the F-score, in addition to visual inspection.</p></sec><sec id="Sec12"><title>Cell coordinate transformation</title><p id="Par27">Each image analysis tool uses a different reference system, resulting in the need to transform their output coordinates to facilitate comparability. In particular, the mark-up images generated by ImageScope, which were utilized in ImageJ to manually obtain the coordinates of detected cells, had different resolutions compared to the original ROIs. To address these variations, a python script was developed to transform all the coordinates onto the same grid, by using the size and resolution of the ROIs and mark-up images.</p></sec><sec id="Sec13"><title>Cell coordinate assignment</title><p id="Par29">To identify the best match between the transformed coordinates of the cells detected by the image analysis tools and the reference standard, we developed another python script that employed the Hungarian algorithm, which is an optimization method used to efficiently find the optimal one-to-one assignment by minimizing the total distance between the two sets of items being matched<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>.</p><p id="Par30">When comparing the dots representing the coordinates of the reference standard with those of each of the image analysis tools, we observed that there was typically no perfect match. One possible explanation for this disparity is that the pathologist (SL) was not asked to mark the center of the tumor cell nuclei and occasionally placed the dot marking on the corner or edge of the tumor cell. The image analysis tools exhibited similar behavior, for technical reasons. To address the un-matching coordinates, we utilized the maximum diameter (based on visual examination) of a tumor cell as the maximum permitted distance between two sets of coordinates during comparison.</p><p id="Par32">The Hungarian algorithm was used to resolve the multi-to-one assignment cases. For instance, when ImageScope detected several tumor cells in an area where the reference standard identified only one tumor cell, the Hungarian algorithm helped to determine the best matched detections. As a result of the assignment process, matched coordinates were considered true positive (TP) detections, unassigned coordinates from the reference standard were considered false negative (FN) detections, and unassigned coordinates from the respective image analysis tool were considered as false positive (FP) detections (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). Furthermore, performance metrics including the false discovery rate (FDR), precision, recall, and F-score were utilized. By utilizing these metrics, in addition to comparing the number of tumor cells detected by the image analysis tools with the reference standard, we were able to evaluate whether each prediction was a correct tumor cell detection.</p><p id="Par33">
<fig id="Fig2"><label>Fig. 2</label><caption><p>Coordinate assignment for detected tumor cells. Red circles show cells detected by the image analysis tool (in this case, Aiforia), black squares show the reference standard. An isolated red circle (green arrow) represents a false positive (FP) tumor cell detection. An isolated black square (yellow arrow) represents a false negative (FN) tumor cell detection. A successful assignment, a true positive (TP) tumor cell detection, is indicated by a black line connecting the respective matching pair of black square and red circle.</p></caption><graphic xlink:href="41598_2025_8778_Fig2_HTML" id="d33e567"/></fig>
</p></sec><sec id="Sec3"><title>Statistical analysis</title><p id="Par34">Statistical analysis was performed using IBM SPSS Statistics (version 26, Armonk, NY, USA, IBM SPSS Statistics). Plots were generated using R (version 4.1.2) within RStudio (version 1.1.463).</p><p id="Par35">The extent of agreement between the results of the image analysis tools and the reference standard was assessed by intra-class correlation coefficient (ICC) with the &#x0201c;two-way mixed&#x0201d; model, based on &#x0201c;single measures&#x0201d; at a 95% confidence interval (CI). The ICC values ranged from 0 (no agreement) to 1 (perfect agreement). A p-value&#x02009;&#x0003c;&#x02009;0.05 was considered statistically significant<sup><xref ref-type="bibr" rid="CR27">27</xref>,<xref ref-type="bibr" rid="CR28">28</xref></sup>.</p><p id="Par36">To evaluate the performance of the image analysis tools, metrics such as the F-score, sensitivity, recall, and FDR were used. Total and Ki67 positive tumor cell detection, as well as the Ki67 score were assessed against the reference standard.</p><p id="Par37">For comparing the values of the performance metrics (FDR, Precision, Recall, F-score) between the two employed image analysis tools,, and their number of tumor cell detections, the paired Wilcoxon signed rank test<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> a non-parametric alternative to the paired t-test, was used. The normal distribution assumption was rejected based on the Shapiro Wilk test.</p><p id="Par38">Bland-Altman plots were employed to visually depict the agreement between the measurements<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>. Since normality of the data distribution was rejected by the Shapiro Wilk test, a non-parametric method was used. Hence, the limits of agreement were estimated using the 2.5th and 97.5th percentiles and the biases were estimated by the median (instead of the mean) of the differences.</p></sec></sec><sec id="Sec4"><title>Results</title><sec id="Sec14"><title>Detection of tumor cells</title><p id="Par40">The evaluation of the two image analysis tools on our test dataset was conducted in three stages. The first stage focused on the detection of total (Ki67 positive and Ki67 negative) tumor cells. When examining the number of detected total tumor cells per ROI, the comparisons of ImageScope and Aiforia against the reference standard revealed moderate and excellent agreement, respectively, with ICC&#x02009;=&#x02009;0.62 (95% CI, 0.44&#x02013;0.75) and p-value&#x02009;=&#x02009;0.0003 (paired Wilcoxon signed rank test) and ICC&#x02009;=&#x02009;0.91 (95% CI, 0.86&#x02013;0.94) and p-value&#x02009;=&#x02009;0.0425 (paired Wilcoxon signed rank test) (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>a). Out of the 80 ROIs, Aiforia over-counted the total number of tumor cells in 65% (52/80) and under-counted in 35% (28/80), whereas ImageScope over-counted in 70% (56/80) and under-counted in 30% (24/80) (Supplementary Table S3 for detailed counts of tumor cells). While the agreement between Aiforia and the reference standard did not reach the same level as that observed in the intra-observer experiment (ICC&#x02009;=&#x02009;0.98, 95% CI, 0.97&#x02013;0.99. Supplementary Fig. <xref rid="MOESM1" ref-type="media">S1</xref>), the results still indicated that Aiforia performed significantly better than ImageScope did.</p><p id="Par41">
<fig id="Fig3"><label>Fig. 3</label><caption><p>Evaluating the performance of computational detection of all tumor cells. (<bold>a</bold>) Scatterplot and fitted regression lines comparing the total number of detected tumor cells between the reference standard (x-axis) and the image analysis tools (y-axis, ImageScope: blue, Aiforia: red). Each dot indicates the tumor cell count in one of the 80 ROIs in the test dataset. The intra-class correlation coefficient (ICC) represents the extent of agreement between the image analysis tools and the reference standard in detecting the total number of tumor cells. The formula of the regression line between the total number of detected tumor cells by each image analysis and the reference standard is shown. This formula provides insights into the linear association between the two measurements. (<bold>b</bold>) Strip chart comparing a set of performance metrics (false discovery rate (FDR), Precision, Recall, F-score) between the two image analysis tools. Each pair of points are linked by a purple line. <italic>P</italic>-values represent the result of paired Wilcoxon signed rank tests. The median for each set of data points is drawn as a short black line on the datapoints. (<bold>c</bold>&#x02013;<bold>e</bold>) A single region of interest, the scale bar represents 60&#x000a0;&#x003bc;m. (<bold>d</bold>&#x02013;<bold>e</bold>) Visualizing total tumor cell detection by the reference standard (black squares) and ImageScope (in <bold>d</bold>, blue circles), and Aiforia (in e, red circles). It is a true positive (TP) detection, for tumor cells, if both the reference standard and the image analysis detection markings are placed on the same cell. A stand-alone black square is a false negative (FN) detection, for tumor cells, and a stand-alone blue (or red) circle is a false positive (FP) detection, for tumor cells.</p></caption><graphic xlink:href="41598_2025_8778_Fig3_HTML" id="d33e648"/></fig>
</p><p id="Par42">Subsequently, we investigated the concordance between image analysis-based tumor cell detection and the reference standard at the level of individual cells, using the four performance metrics (FDR, precision, recall, and F-score). All four metrics were significantly better for Aiforia as compared to ImageScope (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>b, Supplementary Table S3).</p><p id="Par43">A visual inspection of the prediction results in the ROIs confirmed that ImageScope often misclassified many cells as tumor cells, resulting in FP detection (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>c, d). Additionally, ImageScope sometimes misidentified overlapping tumor cells as one large cell, leading to FN detection (Supplementary Fig. <xref rid="MOESM2" ref-type="media">S2</xref>, Supplementary Table S3 for detailed counts of tumor cells). In some cases, the Aiforia algorithm appeared slightly conservative, causing it to miss some true tumor cells, resulting in FN detection (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>c, e).</p><p id="Par44">In summary, when evaluated for all tumor cells, Aiforia (FDR&#x02009;=&#x02009;0.13, precision&#x02009;=&#x02009;0.87, recall&#x02009;=&#x02009;0.90, F-score&#x02009;=&#x02009;0.90) presented substantially better agreement with the reference standard as compared to ImageScope (FDR&#x02009;=&#x02009;0.30, precision&#x02009;=&#x02009;0.70, recall&#x02009;=&#x02009;0.79, F-score&#x02009;=&#x02009;0.74).</p></sec><sec id="Sec15"><title>Detection of Ki67 positive tumor cells</title><p id="Par46">In the second step of the evaluation, we examined the detection of Ki67 positive tumor cells in each of the 80 ROIs. The agreement of ImageScope and Aiforia with the reference standard was poor and moderate, respectively, with ICC&#x02009;=&#x02009;0.24 (95% CI, 0.005&#x02013;0.44) and ICC&#x02009;=&#x02009;0.70 (95% CI, 0.46&#x02013;0.82). Out of the 80 ROIs, Aiforia over-counted the number of Ki67 positive tumor cells in 51% (41/80), under-counted in 6% (5/80), and got matching results in 43% (34/80), whereas ImageScope over-counted in 70% (56/80) and obtained matching results with the reference standard in 30% (24/80) of the ROIs (Supplementary Table S4).</p><p id="Par47">Compared with both the reference standard and Aiforia, ImageScope generally classified almost all positively Ki67-stained cells as Ki67 positive tumor cells, resulting in a higher count. While Aiforia exhibited a slightly more conservative approach than ImageScope in detecting positively Ki67-stained tumor cells, it still counted more compared to the reference standard (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>a). Based on the number of detected Ki67 positive tumor cells, four performance metrics were calculated for each case. While Aiforia generally showed better values in three out of the four measures (FDR, precision, and F-score), the differences in performance between Aiforia and ImageScope were not statistically significant (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>b).</p><p id="Par48">
<fig id="Fig4"><label>Fig. 4</label><caption><p>Evaluating the performance of computational detection of Ki67 positive tumor cells. (<bold>a</bold>) Scatterplot showing the distribution of the detected Ki67 positive tumor cells by the reference standard (black squares), ImageScope (blue circles), and Aiforia (red circles), each set of points (linked by a purple line) shows the result across the 10 cases, where an individual point indicates the sum of Ki67 positive tumor cell counts in the eight ROIs for the respective case. (<bold>b</bold>) Strip chart comparing a set of performance metrics (false discovery rate (FDR), precision, recall, F-score) between the two image analysis tools. Each pair of points (linked by a purple line) represents the sum of Ki67 positive tumor cell counts for one of the 10 cases with the respective tool (ImageScope: blue, Aiforia: red). <italic>P</italic>-values represent the results of paired Wilcoxon signed rank tests. The median for each set of data points is drawn as a short black line on the datapoints. (<bold>c</bold>&#x02013;<bold>e</bold>) A single region of interest, the scale bar is 60&#x000a0;&#x003bc;m. (<bold>d</bold>&#x02013;<bold>e</bold>) Visualization of Ki67 positive tumor cell detection by reference standard (black squares), ImageScope (in<bold> d</bold>, with blue circles), and Aiforia (in<bold> e</bold>, with red circles). It is a true positive (TP) detection, of a Ki67 positive tumor cell, if both the reference standard and the image analysis detection markings are placed on the same cell. A stand-alone black square is a false negative (FN) detection, for a Ki67 positive tumor cell, and a stand-alone blue (or red) circle is a false positive (FP) detection, for a Ki67 positive tumor cell.</p></caption><graphic xlink:href="41598_2025_8778_Fig4_HTML" id="d33e717"/></fig>
</p><p id="Par49">Visual inspection revealed that ImageScope tended to split a cell into several smaller parts, which could be due to inhomogeneous staining throughout the cell (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>c, d and Supplementary Fig. S3). This splitting of cells was more noticeable in the positively Ki67-stained cells and contributed to the higher count of Ki67 positive tumor cells by ImageScope.</p><p id="Par50">Although Aiforia performed better than ImageScope, it still exhibited some errors. It occasionally misclassified Ki67 positive interstitial (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>c, e) and other Ki67 positive non-tumor cells as Ki67 positive tumor cells or detected faintly stained Ki67 positive tumor cells that were dismissed by the pathologist (SL), resulting in FP detections (Supplementary Fig. S3).</p><p id="Par51">In summary, when evaluated for Ki67 positive tumor cells, Aiforia (FDR&#x02009;=&#x02009;0.42, precision&#x02009;=&#x02009;0.58, recall&#x02009;=&#x02009;0.88, F-score&#x02009;=&#x02009;0.70) demonstrated better agreement with the reference standard as compared to ImageScope (FDR&#x02009;=&#x02009;0.61, precision&#x02009;=&#x02009;0.39, recall&#x02009;=&#x02009;0.98, F-score&#x02009;=&#x02009;0.55). However, the differences in performance between the two image analysis tools were not statistically significant.</p></sec><sec id="Sec16"><title>Ki67 score</title><p id="Par53">For the third step of the evaluation, we compared the Ki67 scores obtained from ImageScope and Aiforia with the reference standard. The agreement between ImageScope and the reference standard was poor, with an ICC&#x02009;=&#x02009;0.45 (95% CI, 0.09&#x02013;0.66). However, Aiforia showed superior agreement with an ICC&#x02009;=&#x02009;0.86 (95% CI, 0.73&#x02013;0.92). Out of the 80 ROIs, Aiforia over-estimated the score in 59% (47/80; in some ROIs the image analysis tool counted the Ki67 positive non-tumor cells, or faintly stained tumor cells as Ki67 positive tumor cells), under-estimated in 21% (17/80; in some ROIs the image analysis tool counted more cells by including several non-tumor cells, while counting the same number of positive tumor cells), and provided concordant results in 20% (16/80; all 16 ROIs had no Ki67 positive cells). Whereas ImageScope over-estimated the score in 76% (61/80), under-estimated in 8% (6/80), and gave concordant results in 16% (13/80; all 13 ROIs had no Ki67 positive tumor cells) of ROIs. Notably, that there was one change in grade (for case number 3) in our test dataset by non-ML analysis, compared with the reference standard. None of the cases analyzed by the ML method changed in grade (Supplementary Table S3 and S4 for individual scores of the cases).</p><p id="Par55">To visually compare the Ki67 scores between the image analysis tools and the reference standard, Bland-Altman plots were created. The plots display the means of the scores on the x axis and the differences in the scores on the y axis for each of the 80 ROIs (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>) and 10 cases (Supplementary Fig. S4). In both plots, the median line and most data points were below zero, indicating that both image analysis tools over-estimated the Ki67 score compared with the reference standard. Some outliers were observed both below and above the limits of agreement. Aiforia has narrower limits of agreements, and its median line is closer to zero. This finding suggests that when comparing the Ki67 scores with the reference standard, Aiforia demonstrated better agreement and reliability than ImageScope.</p><p id="Par56">
<fig id="Fig5"><label>Fig. 5</label><caption><p>Bland-Altman plot showing the agreement of Ki67 scores between the reference standard (RS) and ImageScope (IS) or Aiforia (AI). The black bold line represents the bias line. The dashed lines are limits of agreement. The x axis shows the average of the score measurements. The y axis shows the difference between the measured scores. (<bold>a</bold>) Agreement between the Ki67 score measured by the reference standard and ImageScope and (<bold>b</bold>) Aiforia for the 80 data points, representing the 80 ROIs in the test dataset. Aiforia has narrower limits of agreements, and its median line is closer to the zero line.</p></caption><graphic xlink:href="41598_2025_8778_Fig5_HTML" id="d33e755"/></fig>
</p></sec></sec><sec id="Sec5"><title>Discussion</title><p id="Par57">Achieving automatic tumor cell detection and Ki67 score estimation is one of the central goals for the application of image analysis in digital pathology. While numerous studies have already addressed the development and evaluation of related image analysis tools<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> many of these studies focused solely on the number of detected cells or the Ki67 score<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. However, even if an image analysis tool returns the correct number of detected cells, the same as the reference standard, it does not guarantee that the correct cells have been identified (Supplementary Table S3 and S4 for detailed counts of tumor cells). The current study aims to evaluate detection results at the individual cell level to fully understand any performance differences. To achieve this, performance of a ML-based and a non-ML-based image analysis tool were evaluated in estimating Ki67 score in NETs. The employed non-ML analysis tool represents an example for the conventional approach with a user-friendly interface. While the chosen ML-based platform, supported by strong customer service, exemplifies the state-of-the-art technology and facilitates easy implementation for first-time users. By emphasizing the importance of correct tumor cell identification, our study provides a more comprehensive and clinically relevant evaluation of image analysis tools, ultimately enhancing their trustworthiness and interpretability.</p><p id="Par58">This study specifically focused on challenging NET cases with a low Ki67 score of less than 5%, as accurate estimation of Ki67 score is particularly important for these low proliferating tumors, where a prognostically significant cut-off value of 3% separates G1 from G2 tumors<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. Misclassifying these cases can have significant therapeutic implication. The WHO recommendation to count 500-2,000 cells is rather vague and does not consider the dependency on the proliferation rate. However, studies in breast cancer have clearly demonstrated that an accurate result depends on both the proliferation rate and the number of cells evaluated<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. Since manually counting such a large number of cells is impractical, an automated method that can assist in differentiating between G1 and G2 NETs can significantly improve workflow efficiency.</p><p id="Par59">This study demonstrated that neither of the two employed image analysis tools displayed perfect performance after comparing their result at the cell level with the reference standard. However, the ML-based analysis with Aiforia exhibited better agreement with the reference standard in both cell detection and Ki67 score calculation compared to the non-ML-based analysis with ImageScope. Furthermore, it was demonstrated that the improved concordance between the Aiforia&#x02019;s Ki67 score, and the reference standard was attributed to its ability to distinguish between tumor and non-tumor cells.</p><p id="Par60">The superior performance of the ML-based tool may stem from its use of supervised learning, which enables it to adapt to the data and learn parameters instead of relying on fixed, predefined parameters<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. However, the performance of Aiforia also showed limitations, manifested by its tendency to pick more positively Ki67-stained cells, including (i) faintly stained Ki67 positive tumor cells which were dismissed by the pathologist (SL), or (ii) Ki67 positively stained proliferating non-tumor cells, resulting in a slightly higher estimated score.</p><p id="Par61">The issue with the detection of faintly stained cells can be attributed to the general difficulty in visually assigning correct labels for weakly stained tumor cells. For those cells, labeling might be highly subjective due to stain quality, section thickness, nucleus appearance, as well as inter-observer and intra-observer variability<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. The issue of non-tumor cell detection could be due to several underlying reasons, such as limited variation in the training dataset, and narrow control over the training procedures and other hyperparameters, which may limit the ability to fine-tune the model. Vesterinen et al.. reported a mildly better agreement between their trained Aiforia model and manual counting<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. This could be due to having a bigger dataset. Another possible factor could be differences in the neural network settings. Additionally, they reported only the Ki67 score and did not provide details about their model&#x02019;s performance in terms of cell counts.</p><p id="Par62">Two main shortcomings in the performance of the non-ML analysis with ImageScope were observed, namely (i) difficulties distinguishing tumor from non-tumor cells, and (ii) issues related to the segmentation of individual cells. Specifically, in the presence of lymphocytes, endothelial cells, and stromal cells, the algorithm would frequently have difficulty distinguishing tumor cells (Supplementary Fig. S5). Depending on the distribution of cell types within a sample, this issue would frequently lead to the over-counting of tumor cells (Supplementary Table S3 and S4 for detailed counts of tumor cells). Non-ML-based analysis tools typically operate with a set of predefined parameters, and thus lack flexibility and adaptability when dealing with complex tasks. One possible solution to address this issue is to limit the scope of analysis, for example to analyze only tumor areas. Using a similar method, Volynskaya et al.. reported that their ImageScope analysis correlated with the pathologists&#x02019; results, after manual removal of the stroma within the analyzed regions<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. While such an approach can improve the analysis results by excluding most non-tumor cells from the analysis, it is more time-consuming and requires domain expertise for precise annotation, making it impractical in our opinion. Other researchers have attempted different strategies, such as (virtual) double staining<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> or finding complementary biomarkers<sup><xref ref-type="bibr" rid="CR37">37</xref>&#x02013;<xref ref-type="bibr" rid="CR39">39</xref></sup> to facilitate distinction between tumor and non-tumor cells.</p><p id="Par63">The second shortcoming in the performance of ImageScope was related to imprecise segmentations. Two main issues were observed in this regard. First, the method often struggled to accurately distinguish overlapping tumor cells, leading to an underestimation of the number of individual tumor cells (Supplementary Fig. <xref rid="MOESM2" ref-type="media">S2</xref>). Secondly, ImageScope faces challenges in correctly segmenting Ki67 positive tumor cells in cases of inhomogeneous staining. This issue resulted in overestimation, where one cell was segmented as multiple objects (Supplementary Fig. S3). One approach to overcome the segmentation problem is to measure the area fraction, which compares the area of brown-stained nuclei to the total area of brown- and blue-stained nuclei<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. However, this solution can be sensitive to tumor type and cell size, making it less universally applicable. While efforts have been made to address this issue<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> a universally applicable solution has not yet emerged.</p><p id="Par64">Our study stands out as one of the few that specifically investigated the use of ML for estimating the Ki67 score in gastroenteropancreatic NETs. Other similar studies have also developed ML models, either using proprietary software<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> or open source software<sup><xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR41">41</xref>,<xref ref-type="bibr" rid="CR42">42</xref></sup>. Using proprietary software, like Aiforia<sup><xref ref-type="bibr" rid="CR43">43</xref>,<xref ref-type="bibr" rid="CR44">44</xref></sup> offers certain advantages, such as fast and reliable customer support and often a more intuitive user interface. These factors make it easier, even for pathologists, to fine-tune an ML model. However, there are potential issues associated with proprietary closed source software, including cost, limited insight and control over individual settings and parameters, and ownership of the final trained model. Conducting similar analyses using open source software provides an alternative approach. In this case, more technical knowledge is required to implement and fine-tune the model, but it avoids the issues associated with proprietary software. The choice between proprietary software and open source software depends on various factors, including the specific requirements of the study, available resources, and the technical expertise of the researchers.</p><p id="Par65">Even though Ki67 staining is a routine procedure in most histology laboratories, there can be a substantial amount of staining variation in terms of the brown color of positively Ki67-stained cells. This variation has the potential to affect prediction results across different slides. While the current study takes into account the presence of stain variations when tuning algorithms, additional approaches specifically targeting this issue could involve the use of stain normalization techniques<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>or virtual Ki67 staining methods<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>. An even more effective strategy could be the application of virtual double Ki67/synaptophysin staining, which not only addresses staining variation, but also helps in identifying tumor cells, facilitating a better distinction between tumor and non-tumor cells<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>.</p><p id="Par66">A common challenge in evaluating automated tumor cell detection tools is the lack of an absolute ground truth for comparison. Instead, an approximative ground truth is usually established by a domain expert. In our study, we considered the manual counting of tumor cells by an experienced gastrointestinal pathologist to be a fair representation of the ground truth. The choice of using only one domain expert in setting the reference standard, i.e., not considering the expected inter-observer variability, could be regarded as an additional limitation. However, we believe this approach is reasonable considering the focus of the study, which is comparing the performance of two image analysis tools in detecting the correct tumor cells.</p><p id="Par67">While hotspot selection is often considered a central step in Ki67 scoring, there are no precise instructions on how to choose a hotspot or assess one; for a discussion of this topic see for example Volynskaya et al.<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. Some studies have explored the reliability of Ki67 scores when averaging several smaller hotspots or using a single larger hotspot<sup><xref ref-type="bibr" rid="CR48">48</xref>&#x02013;<xref ref-type="bibr" rid="CR51">51</xref></sup>while others have employed automatic hotspots selection<sup><xref ref-type="bibr" rid="CR52">52</xref>&#x02013;<xref ref-type="bibr" rid="CR54">54</xref></sup>. Since the Ki67 score is affected both by the number and size of chosen hotspots, any differences in these parameters between the compared methods could make direct comparison unreliable. In light of these issues, we chose to use the term ROI rather than the term hotspot and decided to define ROIs with a standard size containing approximately 200 cells, which was considered adequate to meet the aim of this study &#x02013; to compare performance&#x02019;s accuracy of two image analysis tools in cell level.</p><p id="Par68">In conclusion, accurately determining the Ki67 score is crucial for grading NETs, predicting patient prognosis, and guiding treatment decisions. The integration of automated image analysis tools in clinical practice can enable pathologists to evaluate larger portion of the biopsy in less time. In the current study, we compared two image analysis tools for cell detection and Ki67 score estimation in NETs with low proliferation index and highlighted the importance of evaluating performance at the individual cell level. In comparison with the chosen reference standard, the ML based image analysis demonstrated a better agreement in correctly detecting individual tumor cells, both Ki67 positive and negative, compared to the non-ML approach, resulting in improved Ki67 score calculation.</p><p id="Par69">Our study is among the few publications that compares image analysis tools in a diagnostic setting at the individual cell level. Unfortunately, there is a lack of comprehensive evaluations and comparisons of image analysis tools, particularly in the rapidly expanding market of commercially available artificial intelligence software. The lack of such evaluations hampers the ability of pathology departments to make informed decisions when purchasing these tools. Additionally, existing publications often provide incomplete assessments of model performance, further highlighting the need for more rigorous and comprehensive evaluations.</p><p id="Par70">In the future, we aim to integrate the ML-based image analysis tool in routine diagnostics. A possible integration scenario can be for ML to flag the borderline cases, those near the G1/G2 threshold, for a more comprehensive manual review. This would help reduce the consequences of systemic bias and misclassification by image analysis tools. It can also output confidence scores, enabling pathologists to focus on low confidence predictions. This will involve further validation studies, including detailed analyses of comprehensive datasets of NET subtypes, outcome studies in patients with NETs, as well as the use of large external tumor datasets to validate the performance of the image analysis tool. Clinical validation, which involves correlating the calculated Ki67 score with clinical outcome data, is another important step to ensure the reliability and usefulness of the algorithm in real-world scenarios.</p></sec><sec id="Sec6" sec-type="supplementary-material"><title>Electronic supplementary material</title><p>Below is the link to the electronic supplementary material.</p><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41598_2025_8778_MOESM1_ESM.pdf"><caption><p>Supplementary Material 1.</p></caption></media></supplementary-material>
</p><p>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41598_2025_8778_MOESM2_ESM.pdf"><caption><p>Supplementary Material 2.</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>We appreciate Anna Knuuttila, Mikael J&#x000e4;&#x000e4;skel&#x000e4;inen, and Darsham Kumar from the Fimmic/Aiforia group for their help with the neural network settings and for patiently answering all our questions.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>S.L. and N.M. were involved in outlining the study concept and design. V.K., and E.H. contributed to methodology development. N.M was responsible for data acquisition, analysis, and writing. S.L. and H.W. were involved in review and revision. H.W. and E.H. provided technical support and data interpretation in statistical analysis. All authors read and approved the final paper.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open access funding provided by University of Bergen. Nazanin Mola was funded by The Western Norway Health Authority [Grant Number 508072 and strategic research fund F12563]. The funder has no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>All the source code used to derive the results presented within this study will be made freely available at https://bit.ly/4glwLlA. The test dataset (80 ROIs), which were reviewed and annotated by an experienced pathologist, will be made available at bit.ly/4kg1sub.</p></notes><notes><title>Declarations</title><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par71">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Rindi</surname><given-names>G</given-names></name><etal/></person-group><article-title>TNM staging of foregut (neuro)endocrine tumors: A consensus proposal including a grading system</article-title><source>Virchows Archiv: Int. J. Pathol.</source><year>2006</year><volume>449</volume><fpage>395</fpage><lpage>401</lpage><pub-id pub-id-type="doi">10.1007/s00428-006-0250-1</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Rindi, G. et al. TNM staging of foregut (neuro)endocrine tumors: A consensus proposal including a grading system. <italic>Virchows Archiv: Int. J. Pathol.</italic><bold>449</bold>, 395&#x02013;401. 10.1007/s00428-006-0250-1 (2006).</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>McCall</surname><given-names>CM</given-names></name><etal/></person-group><article-title>Grading of well-differentiated pancreatic neuroendocrine tumors is improved by the inclusion of both Ki67 proliferative index and mitotic rate</article-title><source>Am. J. Surg. Pathol.</source><year>2013</year><volume>37</volume><fpage>1671</fpage><lpage>1677</lpage><pub-id pub-id-type="doi">10.1097/pas.0000000000000089</pub-id><pub-id pub-id-type="pmid">24121170</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">McCall, C. M. et al. Grading of well-differentiated pancreatic neuroendocrine tumors is improved by the inclusion of both Ki67 proliferative index and mitotic rate. <italic>Am. J. Surg. Pathol.</italic><bold>37</bold>, 1671&#x02013;1677. 10.1097/pas.0000000000000089 (2013).<pub-id pub-id-type="pmid">24121170</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>MS</given-names></name><etal/></person-group><article-title>A comparison of Ki-67 and mitotic count as prognostic markers for metastatic pancreatic and midgut neuroendocrine neoplasms</article-title><source>Br. J. Cancer</source><year>2013</year><volume>108</volume><fpage>1838</fpage><lpage>1845</lpage><pub-id pub-id-type="doi">10.1038/bjc.2013.156</pub-id><pub-id pub-id-type="pmid">23579216</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Khan, M. S. et al. A comparison of Ki-67 and mitotic count as prognostic markers for metastatic pancreatic and midgut neuroendocrine neoplasms. <italic>Br. J. Cancer</italic>. <bold>108</bold>, 1838&#x02013;1845. 10.1038/bjc.2013.156 (2013).<pub-id pub-id-type="pmid">23579216</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Christgen</surname><given-names>M</given-names></name><name><surname>von Ahsen</surname><given-names>S</given-names></name><name><surname>Christgen</surname><given-names>H</given-names></name><name><surname>L&#x000e4;nger</surname><given-names>F</given-names></name><name><surname>Kreipe</surname><given-names>H</given-names></name></person-group><article-title>The region-of-interest size impacts on Ki67 quantification by computer-assisted image analysis in breast cancer</article-title><source>Hum. Pathol.</source><year>2015</year><volume>46</volume><fpage>1341</fpage><lpage>1349</lpage><pub-id pub-id-type="doi">10.1016/j.humpath.2015.05.016</pub-id><pub-id pub-id-type="pmid">26206765</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Christgen, M., von Ahsen, S., Christgen, H., L&#x000e4;nger, F. &#x00026; Kreipe, H. The region-of-interest size impacts on Ki67 quantification by computer-assisted image analysis in breast cancer. <italic>Hum. Pathol.</italic><bold>46</bold>, 1341&#x02013;1349. 10.1016/j.humpath.2015.05.016 (2015).<pub-id pub-id-type="pmid">26206765</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Rindi</surname><given-names>G</given-names></name><etal/></person-group><article-title>A common classification framework for neuroendocrine neoplasms: an international agency for research on cancer (IARC) and world health organization (WHO) expert consensus proposal</article-title><source>Mod. Pathology: Offi. J. United States Can. Acad. Pathol. Inc</source><year>2018</year><volume>31</volume><fpage>1770</fpage><lpage>1786</lpage><pub-id pub-id-type="doi">10.1038/s41379-018-0110-y</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Rindi, G. et al. A common classification framework for neuroendocrine neoplasms: an international agency for research on cancer (IARC) and world health organization (WHO) expert consensus proposal. <italic>Mod. Pathology: Offi. J. United States Can. Acad. Pathol. Inc</italic><bold>31</bold>, 1770&#x02013;1786. 10.1038/s41379-018-0110-y (2018).</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Perren</surname><given-names>A</given-names></name><etal/></person-group><article-title>ENETS consensus guidelines for the standards of care in neuroendocrine tumors: pathology: Diagnosis and prognostic stratification</article-title><source>Neuroendocrinology</source><year>2017</year><volume>105</volume><fpage>196</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1159/000457956</pub-id><pub-id pub-id-type="pmid">28190015</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Perren, A. et al. ENETS consensus guidelines for the standards of care in neuroendocrine tumors: pathology: Diagnosis and prognostic stratification. <italic>Neuroendocrinology</italic><bold>105</bold>, 196&#x02013;200. 10.1159/000457956 (2017).<pub-id pub-id-type="pmid">28190015</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Going</surname><given-names>JJ</given-names></name></person-group><article-title>Techniques of mitosis counting</article-title><source>Hum. Pathol.</source><year>1993</year><volume>24</volume><fpage>113</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/0046-8177(93)90072-o</pub-id><pub-id pub-id-type="pmid">8352828</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Going, J. J. Techniques of mitosis counting. <italic>Hum. Pathol.</italic><bold>24</bold>, 113&#x02013;114. 10.1016/0046-8177(93)90072-o (1993).<pub-id pub-id-type="pmid">8352828</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Besusparis</surname><given-names>J</given-names></name><etal/></person-group><article-title>Impact of tissue sampling on accuracy of Ki67 immunohistochemistry evaluation in breast cancer</article-title><source>Diagn. Pathol.</source><year>2016</year><volume>11</volume><fpage>82</fpage><pub-id pub-id-type="doi">10.1186/s13000-016-0525-z</pub-id><pub-id pub-id-type="pmid">27576949</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Besusparis, J. et al. Impact of tissue sampling on accuracy of Ki67 immunohistochemistry evaluation in breast cancer. <italic>Diagn. Pathol.</italic><bold>11</bold>, 82. 10.1186/s13000-016-0525-z (2016).<pub-id pub-id-type="pmid">27576949</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Bonert</surname><given-names>M</given-names></name><etal/></person-group><article-title>Evolution of anatomic pathology workload from 2011 to 2019 assessed in a regional hospital laboratory via 574,093 pathology reports</article-title><source>PLoS One</source><year>2021</year><volume>16</volume><fpage>e0253876</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0253876</pub-id><pub-id pub-id-type="pmid">34185808</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Bonert, M. et al. Evolution of anatomic pathology workload from 2011 to 2019 assessed in a regional hospital laboratory via 574,093 pathology reports. <italic>PLoS One</italic>. <bold>16</bold>, e0253876. 10.1371/journal.pone.0253876 (2021).<pub-id pub-id-type="pmid">34185808</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>HT</given-names></name><etal/></person-group><article-title>Accuracy of visual assessments of proliferation indices in gastroenteropancreatic neuroendocrine tumours</article-title><source>J. Clin. Pathol.</source><year>2013</year><volume>66</volume><fpage>700</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1136/jclinpath-2012-201217</pub-id><pub-id pub-id-type="pmid">23703851</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Young, H. T. et al. Accuracy of visual assessments of proliferation indices in gastroenteropancreatic neuroendocrine tumours. <italic>J. Clin. Pathol.</italic><bold>66</bold>, 700&#x02013;704. 10.1136/jclinpath-2012-201217 (2013).<pub-id pub-id-type="pmid">23703851</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Warth</surname><given-names>A</given-names></name><etal/></person-group><article-title>Interobserver agreement of proliferation index (Ki-67) outperforms mitotic count in pulmonary carcinoids</article-title><source>Virchows Archiv: Int. J. Pathol.</source><year>2013</year><volume>462</volume><fpage>507</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1007/s00428-013-1408-2</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Warth, A. et al. Interobserver agreement of proliferation index (Ki-67) outperforms mitotic count in pulmonary carcinoids. <italic>Virchows Archiv: Int. J. Pathol.</italic><bold>462</bold>, 507&#x02013;513. 10.1007/s00428-013-1408-2 (2013).</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Reid</surname><given-names>MD</given-names></name><etal/></person-group><article-title>Calculation of the Ki67 index in pancreatic neuroendocrine tumors: a comparative analysis of four counting methodologies</article-title><source>Mod. Pathology: Official J. United States Can. Acad. Pathol. Inc</source><year>2015</year><volume>28</volume><fpage>686</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1038/modpathol.2014.156</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Reid, M. D. et al. Calculation of the Ki67 index in pancreatic neuroendocrine tumors: a comparative analysis of four counting methodologies. <italic>Mod. Pathology: Official J. United States Can. Acad. Pathol. Inc</italic>. <bold>28</bold>, 686&#x02013;694. 10.1038/modpathol.2014.156 (2015).</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Aeffner</surname><given-names>F</given-names></name><etal/></person-group><article-title>Introduction to digital image analysis in whole-slide imaging: A white paper from the digital pathology association</article-title><source>J. Pathol. Inf.</source><year>2019</year><volume>10</volume><fpage>9</fpage><pub-id pub-id-type="doi">10.4103/jpi.jpi_82_18</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Aeffner, F. et al. Introduction to digital image analysis in whole-slide imaging: A white paper from the digital pathology association. <italic>J. Pathol. Inf.</italic><bold>10</bold>, 9. 10.4103/jpi.jpi_82_18 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Madabhushi</surname><given-names>A</given-names></name></person-group><article-title>Digital pathology image analysis: Opportunities and challenges</article-title><source>Imaging Med.</source><year>2009</year><volume>1</volume><fpage>7</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.2217/iim.09.9</pub-id><pub-id pub-id-type="pmid">30147749</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Madabhushi, A. Digital pathology image analysis: Opportunities and challenges. <italic>Imaging Med.</italic><bold>1</bold>, 7&#x02013;10. 10.2217/iim.09.9 (2009).<pub-id pub-id-type="pmid">30147749</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Moscalu, M. et al. Histopathological images analysis and predictive modeling implemented in digital pathology&#x02014;current affairs and perspectives. <italic>Diagnostics</italic><bold>13</bold> (2023).</mixed-citation></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Acs</surname><given-names>B</given-names></name><etal/></person-group><article-title>Ki67 reproducibility using digital image analysis: An inter-platform and inter-operator study</article-title><source>Lab. Invest.</source><year>2019</year><volume>99</volume><fpage>107</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1038/s41374-018-0123-7</pub-id><pub-id pub-id-type="pmid">30181553</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Acs, B. et al. Ki67 reproducibility using digital image analysis: An inter-platform and inter-operator study. <italic>Lab. Invest.</italic><bold>99</bold>, 107&#x02013;117. 10.1038/s41374-018-0123-7 (2019).<pub-id pub-id-type="pmid">30181553</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Wang, S. et al. Artificial intelligence in lung Cancer pathology image analysis. <italic>Cancers (Basel)</italic><bold>11</bold>. 10.3390/cancers11111673 (2019).</mixed-citation></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Skrede</surname><given-names>OJ</given-names></name><etal/></person-group><article-title>Deep learning for prediction of colorectal cancer outcome: a discovery and validation study</article-title><source>Lancet</source><year>2020</year><volume>395</volume><fpage>350</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1016/s0140-6736(19)32998-8</pub-id><pub-id pub-id-type="pmid">32007170</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Skrede, O. J. et al. Deep learning for prediction of colorectal cancer outcome: a discovery and validation study. <italic>Lancet</italic><bold>395</bold>, 350&#x02013;360. 10.1016/s0140-6736(19)32998-8 (2020).<pub-id pub-id-type="pmid">32007170</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Luchini</surname><given-names>C</given-names></name><etal/></person-group><article-title>Ki-67 assessment of pancreatic neuroendocrine neoplasms: Systematic review and meta-analysis of manual vs. digital pathology scoring</article-title><source>Mod. Pathology: Official J. United States Can. Acad. Pathol. Inc</source><year>2022</year><volume>35</volume><fpage>712</fpage><lpage>720</lpage><pub-id pub-id-type="doi">10.1038/s41379-022-01055-1</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Luchini, C. et al. Ki-67 assessment of pancreatic neuroendocrine neoplasms: Systematic review and meta-analysis of manual vs. digital pathology scoring. <italic>Mod. Pathology: Official J. United States Can. Acad. Pathol. Inc</italic>. <bold>35</bold>, 712&#x02013;720. 10.1038/s41379-022-01055-1 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Skjervold</surname><given-names>AH</given-names></name><name><surname>Pettersen</surname><given-names>HS</given-names></name><name><surname>Valla</surname><given-names>M</given-names></name><name><surname>Opdahl</surname><given-names>S</given-names></name><name><surname>Bofin</surname><given-names>AM</given-names></name></person-group><article-title>Visual and digital assessment of Ki-67 in breast cancer tissue - a comparison of methods</article-title><source>Diagn. Pathol.</source><year>2022</year><volume>17</volume><fpage>45</fpage><pub-id pub-id-type="doi">10.1186/s13000-022-01225-4</pub-id><pub-id pub-id-type="pmid">35524221</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Skjervold, A. H., Pettersen, H. S., Valla, M., Opdahl, S. &#x00026; Bofin, A. M. Visual and digital assessment of Ki-67 in breast cancer tissue - a comparison of methods. <italic>Diagn. Pathol.</italic><bold>17</bold>, 45. 10.1186/s13000-022-01225-4 (2022).<pub-id pub-id-type="pmid">35524221</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>F</given-names></name><name><surname>Yang</surname><given-names>L</given-names></name></person-group><article-title>Robust nucleus/cell detection and segmentation in digital pathology and microscopy images: A comprehensive review</article-title><source>IEEE Rev. Biomed. Eng.</source><year>2016</year><volume>9</volume><fpage>234</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1109/rbme.2016.2515127</pub-id><pub-id pub-id-type="pmid">26742143</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Xing, F. &#x00026; Yang, L. Robust nucleus/cell detection and segmentation in digital pathology and microscopy images: A comprehensive review. <italic>IEEE Rev. Biomed. Eng.</italic><bold>9</bold>, 234&#x02013;263. 10.1109/rbme.2016.2515127 (2016).<pub-id pub-id-type="pmid">26742143</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>RC</given-names></name><etal/></person-group><article-title>Artificial intelligence in breast cancer histopathology</article-title><source>Histopathology</source><year>2023</year><volume>82</volume><fpage>198</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1111/his.14820</pub-id><pub-id pub-id-type="pmid">36482271</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Chan, R. C. et al. Artificial intelligence in breast cancer histopathology. <italic>Histopathology</italic><bold>82</bold>, 198&#x02013;210. 10.1111/his.14820 (2023).<pub-id pub-id-type="pmid">36482271</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumoto</surname><given-names>H</given-names></name><etal/></person-group><article-title>Ki-67 evaluation using deep-learning model-assisted digital image analysis in breast cancer</article-title><source>Histopathology</source><year>2025</year><volume>86</volume><fpage>460</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1111/his.15356</pub-id><pub-id pub-id-type="pmid">39478421</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Matsumoto, H. et al. Ki-67 evaluation using deep-learning model-assisted digital image analysis in breast cancer. <italic>Histopathology</italic><bold>86</bold>, 460&#x02013;471. 10.1111/his.15356 (2025). <ext-link ext-link-type="uri" xlink:href="https://doi.org:">https://doi.org:</ext-link><pub-id pub-id-type="pmid">39478421</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Schneider, C. A., Rasband, W. S. &#x00026; Eliceiri, K. W. NIH image to imageJ: 25 years of image analysis. <italic>Nat. Methods</italic>. 671&#x02013;675 (2012).</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Aperio Technologies, I. <italic>IHC Nuclear Image Analysis, User&#x02019;s Guide</italic> &#x02009;(2007). <ext-link ext-link-type="uri" xlink:href="http://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/1/3053/files/2021/06/MAN-0338-Rev-A.pdf">http://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/1/3053/files/2021/06/MAN-0338-Rev-A.pdf</ext-link>.</mixed-citation></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Kume</surname><given-names>A</given-names></name><name><surname>Walker</surname><given-names>SG</given-names></name></person-group><article-title>The utility of clusters and a Hungarian clustering algorithm</article-title><source>PLoS One</source><year>2021</year><volume>16</volume><fpage>e0255174</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0255174</pub-id><pub-id pub-id-type="pmid">34347837</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Kume, A. &#x00026; Walker, S. G. The utility of clusters and a Hungarian clustering algorithm. <italic>PLoS One</italic><bold>16</bold>, e0255174. 10.1371/journal.pone.0255174 (2021).<pub-id pub-id-type="pmid">34347837</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Koo</surname><given-names>TK</given-names></name><name><surname>Li</surname><given-names>MY</given-names></name></person-group><article-title>A guideline of selecting and reporting intraclass correlation coefficients for reliability research</article-title><source>J. Chiropr. Med.</source><year>2016</year><volume>15</volume><fpage>155</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1016/j.jcm.2016.02.012</pub-id><pub-id pub-id-type="pmid">27330520</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">Koo, T. K. &#x00026; Li, M. Y. A guideline of selecting and reporting intraclass correlation coefficients for reliability research. <italic>J. Chiropr. Med.</italic><bold>15</bold>, 155&#x02013;163. 10.1016/j.jcm.2016.02.012 (2016).<pub-id pub-id-type="pmid">27330520</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganathan</surname><given-names>P</given-names></name><name><surname>Pramesh</surname><given-names>CS</given-names></name><name><surname>Aggarwal</surname><given-names>R</given-names></name></person-group><article-title>Common pitfalls in statistical analysis: Measures of agreement</article-title><source>Perspect. Clin. Res.</source><year>2017</year><volume>8</volume><fpage>187</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.4103/picr.PICR_123_17</pub-id><pub-id pub-id-type="pmid">29109937</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">Ranganathan, P., Pramesh, C. S. &#x00026; Aggarwal, R. Common pitfalls in statistical analysis: Measures of agreement. <italic>Perspect. Clin. Res.</italic><bold>8</bold>, 187&#x02013;191. 10.4103/picr.PICR_123_17 (2017).<pub-id pub-id-type="pmid">29109937</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>du Prel</surname><given-names>JB</given-names></name><name><surname>R&#x000f6;hrig</surname><given-names>B</given-names></name><name><surname>Hommel</surname><given-names>G</given-names></name><name><surname>Blettner</surname><given-names>M</given-names></name></person-group><article-title>Choosing statistical tests: Part 12 of a series on evaluation of scientific publications</article-title><source>Dtsch. Arztebl Int.</source><year>2010</year><volume>107</volume><fpage>343</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.3238/arztebl.2010.0343</pub-id><pub-id pub-id-type="pmid">20532129</pub-id>
</element-citation><mixed-citation id="mc-CR29" publication-type="journal">du Prel, J. B., R&#x000f6;hrig, B., Hommel, G. &#x00026; Blettner, M. Choosing statistical tests: Part 12 of a series on evaluation of scientific publications. <italic>Dtsch. Arztebl Int.</italic><bold>107</bold>, 343&#x02013;348. 10.3238/arztebl.2010.0343 (2010).<pub-id pub-id-type="pmid">20532129</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Giavarina</surname><given-names>D</given-names></name></person-group><article-title>Understanding bland Altman analysis</article-title><source>Biochem. Med. (Zagreb)</source><year>2015</year><volume>25</volume><fpage>141</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.11613/BM.2015.015</pub-id><pub-id pub-id-type="pmid">26110027</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Giavarina, D. Understanding bland Altman analysis. <italic>Biochem. Med. (Zagreb)</italic> , 141&#x02013;151. 10.11613/BM.2015.015 (2015).<pub-id pub-id-type="pmid">26110027</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Bland</surname><given-names>JM</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><article-title>Statistical methods for assessing agreement between two methods of clinical measurement</article-title><source>Lancet</source><year>1986</year><volume>1</volume><fpage>307</fpage><lpage>310</lpage><pub-id pub-id-type="pmid">2868172</pub-id>
</element-citation><mixed-citation id="mc-CR31" publication-type="journal">Bland, J. M. &#x00026; Altman, D. G. Statistical methods for assessing agreement between two methods of clinical measurement. <italic>Lancet</italic><bold>1</bold>, 307&#x02013;310 (1986).<pub-id pub-id-type="pmid">2868172</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Govind</surname><given-names>D</given-names></name><etal/></person-group><article-title>Improving the accuracy of gastrointestinal neuroendocrine tumor grading with deep learning</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><fpage>11064</fpage><pub-id pub-id-type="doi">10.1038/s41598-020-67880-z</pub-id><pub-id pub-id-type="pmid">32632119</pub-id>
</element-citation><mixed-citation id="mc-CR32" publication-type="journal">Govind, D. et al. Improving the accuracy of Gastrointestinal neuroendocrine tumor grading with deep learning. <italic>Sci. Rep.</italic><bold>10</bold>, 11064. 10.1038/s41598-020-67880-z (2020).<pub-id pub-id-type="pmid">32632119</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Vesterinen</surname><given-names>T</given-names></name><etal/></person-group><article-title>Automated assessment of Ki-67 proliferation index in neuroendocrine tumors by deep learning</article-title><source>Apmis</source><year>2022</year><volume>130</volume><fpage>11</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1111/apm.13190</pub-id><pub-id pub-id-type="pmid">34741788</pub-id>
</element-citation><mixed-citation id="mc-CR33" publication-type="journal">Vesterinen, T. et al. Automated assessment of Ki-67 proliferation index in neuroendocrine tumors by deep learning. <italic>Apmis</italic><bold>130</bold>, 11&#x02013;20. 10.1111/apm.13190 (2022).<pub-id pub-id-type="pmid">34741788</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name><surname>Greener</surname><given-names>JG</given-names></name><name><surname>Kandathil</surname><given-names>SM</given-names></name><name><surname>Moffat</surname><given-names>L</given-names></name><name><surname>Jones</surname><given-names>DT</given-names></name></person-group><article-title>A guide to machine learning for biologists</article-title><source>Nat. Rev. Mol. Cell Biol.</source><year>2022</year><volume>23</volume><fpage>40</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1038/s41580-021-00407-0</pub-id><pub-id pub-id-type="pmid">34518686</pub-id>
</element-citation><mixed-citation id="mc-CR34" publication-type="journal">Greener, J. G., Kandathil, S. M., Moffat, L. &#x00026; Jones, D. T. A guide to machine learning for biologists. <italic>Nat. Rev. Mol. Cell Biol.</italic><bold>23</bold>, 40&#x02013;55. 10.1038/s41580-021-00407-0 (2022).<pub-id pub-id-type="pmid">34518686</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Dy</surname><given-names>A</given-names></name><etal/></person-group><article-title>AI improves accuracy, agreement and efficiency of pathologists for Ki67 assessments in breast cancer</article-title><source>Sci. Rep.</source><year>2024</year><volume>14</volume><fpage>1283</fpage><pub-id pub-id-type="doi">10.1038/s41598-024-51723-2</pub-id><pub-id pub-id-type="pmid">38218973</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Dy, A. et al. AI improves accuracy, agreement and efficiency of pathologists for Ki67 assessments in breast cancer. <italic>Sci. Rep.</italic><bold>14</bold>, 1283. 10.1038/s41598-024-51723-2 (2024).<pub-id pub-id-type="pmid">38218973</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Volynskaya</surname><given-names>Z</given-names></name><name><surname>Mete</surname><given-names>O</given-names></name><name><surname>Pakbaz</surname><given-names>S</given-names></name><name><surname>Al-Ghamdi</surname><given-names>D</given-names></name><name><surname>Asa</surname><given-names>SL</given-names></name></person-group><article-title>Ki67 quantitative interpretation: insights using image analysis</article-title><source>J. Pathol. Inf.</source><year>2019</year><volume>10</volume><fpage>8</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.4103/jpi.jpi_76_18</pub-id></element-citation><mixed-citation id="mc-CR36" publication-type="journal">Volynskaya, Z., Mete, O., Pakbaz, S., Al-Ghamdi, D. &#x00026; Asa, S. L. Ki67 quantitative interpretation: insights using image analysis. <italic>J. Pathol. Inf.</italic><bold>10</bold>, 8&#x02013;8. 10.4103/jpi.jpi_76_18 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name><surname>Hacking</surname><given-names>SM</given-names></name><etal/></person-group><article-title>Potential pitfalls in diagnostic digital image analysis: Experience with Ki-67 and PHH3 in gastrointestinal neuroendocrine tumors</article-title><source>Pathol. Res. Pract.</source><year>2020</year><volume>216</volume><fpage>152753</fpage><pub-id pub-id-type="doi">10.1016/j.prp.2019.152753</pub-id><pub-id pub-id-type="pmid">31761497</pub-id>
</element-citation><mixed-citation id="mc-CR37" publication-type="journal">Hacking, S. M. et al. Potential pitfalls in diagnostic digital image analysis: Experience with Ki-67 and PHH3 in gastrointestinal neuroendocrine tumors. <italic>Pathol. Res. Pract.</italic><bold>216</bold>, 152753. 10.1016/j.prp.2019.152753 (2020).<pub-id pub-id-type="pmid">31761497</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>W</given-names></name><name><surname>Nebiolo</surname><given-names>C</given-names></name><name><surname>Esbona</surname><given-names>K</given-names></name><name><surname>Hu</surname><given-names>R</given-names></name><name><surname>Lloyd</surname><given-names>R</given-names></name></person-group><article-title>Ki67 index and mitotic count: Correlation and variables affecting the accuracy of the quantification in endocrine/neuroendocrine tumors</article-title><source>Ann. Diagn. Pathol.</source><year>2020</year><volume>48</volume><fpage>151586</fpage><pub-id pub-id-type="doi">10.1016/j.anndiagpath.2020.151586</pub-id><pub-id pub-id-type="pmid">32836178</pub-id>
</element-citation><mixed-citation id="mc-CR38" publication-type="journal">Huang, W., Nebiolo, C., Esbona, K., Hu, R. &#x00026; Lloyd, R. Ki67 index and mitotic count: Correlation and variables affecting the accuracy of the quantification in endocrine/neuroendocrine tumors. <italic>Ann. Diagn. Pathol.</italic><bold>48</bold>, 151586. 10.1016/j.anndiagpath.2020.151586 (2020).<pub-id pub-id-type="pmid">32836178</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name><surname>Lea</surname><given-names>D</given-names></name><etal/></person-group><article-title>Digital image analysis of the proliferation markers Ki67 and phosphohistone H3 in gastroenteropancreatic neuroendocrine neoplasms: accuracy of grading compared with routine manual hot spot evaluation of the Ki67 index</article-title><source>Appl. Immunohistochem. Mol. Morphology</source><year>2021</year><volume>29</volume><fpage>499</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1097/pai.0000000000000934</pub-id></element-citation><mixed-citation id="mc-CR39" publication-type="journal">Lea, D. et al. Digital image analysis of the proliferation markers Ki67 and phosphohistone H3 in gastroenteropancreatic neuroendocrine neoplasms: accuracy of grading compared with routine manual hot spot evaluation of the Ki67 index. <italic>Appl. Immunohistochem. Mol. Morphology</italic>. <bold>29</bold>, 499&#x02013;505. 10.1097/pai.0000000000000934 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name><surname>Kroneman</surname><given-names>TN</given-names></name><etal/></person-group><article-title>Comparison of three Ki-67 index quantification methods and clinical significance in pancreatic neuroendocrine tumors</article-title><source>Endocr. Pathol.</source><year>2015</year><volume>26</volume><fpage>255</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1007/s12022-015-9379-2</pub-id><pub-id pub-id-type="pmid">26072124</pub-id>
</element-citation><mixed-citation id="mc-CR40" publication-type="journal">Kroneman, T. N. et al. Comparison of three Ki-67 index quantification methods and clinical significance in pancreatic neuroendocrine tumors. <italic>Endocr. Pathol.</italic><bold>26</bold>, 255&#x02013;262. 10.1007/s12022-015-9379-2 (2015).<pub-id pub-id-type="pmid">26072124</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name><surname>Niazi</surname><given-names>MKK</given-names></name><etal/></person-group><article-title>Identifying tumor in pancreatic neuroendocrine neoplasms from Ki67 images using transfer learning</article-title><source>PLoS One</source><year>2018</year><volume>13</volume><fpage>e0195621</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0195621</pub-id><pub-id pub-id-type="pmid">29649302</pub-id>
</element-citation><mixed-citation id="mc-CR41" publication-type="journal">Niazi, M. K. K. et al. Identifying tumor in pancreatic neuroendocrine neoplasms from Ki67 images using transfer learning. <italic>PLoS One</italic><bold>13</bold>, e0195621. 10.1371/journal.pone.0195621 (2018).<pub-id pub-id-type="pmid">29649302</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>F</given-names></name><name><surname>Cornish</surname><given-names>TC</given-names></name><name><surname>Bennett</surname><given-names>T</given-names></name><name><surname>Ghosh</surname><given-names>D</given-names></name><name><surname>Yang</surname><given-names>L</given-names></name></person-group><article-title>Pixel-to-pixel learning with weak supervision for single-stage nucleus recognition in Ki67 images</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2019</year><volume>66</volume><fpage>3088</fpage><lpage>3097</lpage><pub-id pub-id-type="doi">10.1109/tbme.2019.2900378</pub-id><pub-id pub-id-type="pmid">30802845</pub-id>
</element-citation><mixed-citation id="mc-CR42" publication-type="journal">Xing, F., Cornish, T. C., Bennett, T., Ghosh, D. &#x00026; Yang, L. Pixel-to-pixel learning with weak supervision for single-Stage nucleus recognition in Ki67 images. <italic>IEEE Trans. Biomed. Eng.</italic><bold>66</bold>, 3088&#x02013;3097. 10.1109/tbme.2019.2900378 (2019).<pub-id pub-id-type="pmid">30802845</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="other">Pai, R. K. et al. Quantitative pathologic analysis of digitized images of colorectal carcinoma improves prediction of recurrence-free survival. <italic>Gastroenterology</italic><bold>163</bold>, 1531&#x02013;1546.e1538. 10.1053/j.gastro.2022.08.025 (2022).</mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Stetzik, L. et al. A novel automated morphological analysis of Iba1&#x02009;+&#x02009;microglia using a deep learning assisted model. <italic>Front. Cell. Neurosci.</italic><bold>16</bold>10.3389/fncel.2022.944875 (2022).</mixed-citation></ref><ref id="CR45"><label>45.</label><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name><surname>Aung</surname><given-names>TN</given-names></name><etal/></person-group><article-title>A new tool for technical standardization of the Ki67 immunohistochemical assay</article-title><source>Mod. Pathol.: Off.J. United States Can. Acad. Pathol. Inc</source><year>2021</year><volume>34</volume><fpage>1261</fpage><lpage>1270</lpage><pub-id pub-id-type="doi">10.1038/s41379-021-00745-6</pub-id></element-citation><mixed-citation id="mc-CR45" publication-type="journal">Aung, T. N. et al. A new tool for technical standardization of the Ki67 immunohistochemical assay. <italic>Mod. Pathol.: Off.J. United States Can. Acad. Pathol. Inc</italic><bold>34</bold>, 1261&#x02013;1270. 10.1038/s41379-021-00745-6 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR46"><label>46.</label><citation-alternatives><element-citation id="ec-CR46" publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Predict Ki-67 positive cells in H&#x00026;E-stained images using deep learning independently from IHC-stained images</article-title><source>Front. Mol. Biosci.</source><year>2020</year><volume>7</volume><fpage>183</fpage><pub-id pub-id-type="doi">10.3389/fmolb.2020.00183</pub-id><pub-id pub-id-type="pmid">32903653</pub-id>
</element-citation><mixed-citation id="mc-CR46" publication-type="journal">Liu, Y. et al. Predict Ki-67 positive cells in H&#x00026;E-stained images using deep learning independently from IHC-stained images. <italic>Front. Mol. Biosci.</italic><bold>7</bold>, 183. 10.3389/fmolb.2020.00183 (2020).<pub-id pub-id-type="pmid">32903653</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR47"><label>47.</label><citation-alternatives><element-citation id="ec-CR47" publication-type="journal"><person-group person-group-type="author"><name><surname>Koopman</surname><given-names>T</given-names></name><name><surname>Buikema</surname><given-names>HJ</given-names></name><name><surname>Hollema</surname><given-names>H</given-names></name><name><surname>de Bock</surname><given-names>GH</given-names></name><name><surname>van der Vegt</surname><given-names>B</given-names></name></person-group><article-title>Digital image analysis of Ki67 proliferation index in breast cancer using virtual dual staining on whole tissue sections: Clinical validation and inter-platform agreement</article-title><source>Breast Cancer Res. Treat.</source><year>2018</year><volume>169</volume><fpage>33</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1007/s10549-018-4669-2</pub-id><pub-id pub-id-type="pmid">29349710</pub-id>
</element-citation><mixed-citation id="mc-CR47" publication-type="journal">Koopman, T., Buikema, H. J., Hollema, H., de Bock, G. H. &#x00026; van der Vegt, B. Digital image analysis of Ki67 proliferation index in breast cancer using virtual dual staining on whole tissue sections: Clinical validation and inter-platform agreement. <italic>Breast Cancer Res. Treat.</italic><bold>169</bold>, 33&#x02013;42. 10.1007/s10549-018-4669-2 (2018).<pub-id pub-id-type="pmid">29349710</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="other">Jang, M. H., Kim, H. J., Chung, Y. R., Lee, Y. &#x00026; Park, S. Y. A comparison of Ki-67 counting methods in luminal breast cancer: The average method vs. the hot spot method. <italic>PloS One</italic><bold>12</bold>, e0172031&#x02013;e0172031. 10.1371/journal.pone.0172031 (2017).</mixed-citation></ref><ref id="CR49"><label>49.</label><citation-alternatives><element-citation id="ec-CR49" publication-type="journal"><person-group person-group-type="author"><name><surname>St&#x000e5;lhammar</surname><given-names>G</given-names></name><etal/></person-group><article-title>Digital image analysis of Ki67 in hot spots is superior to both manual Ki67 and mitotic counts in breast cancer</article-title><source>Histopathology</source><year>2018</year><volume>72</volume><fpage>974</fpage><lpage>989</lpage><pub-id pub-id-type="doi">10.1111/his.13452</pub-id><pub-id pub-id-type="pmid">29220095</pub-id>
</element-citation><mixed-citation id="mc-CR49" publication-type="journal">St&#x000e5;lhammar, G. et al. Digital image analysis of Ki67 in hot spots is superior to both manual Ki67 and mitotic counts in breast cancer. <italic>Histopathology</italic><bold>72</bold>, 974&#x02013;989. 10.1111/his.13452 (2018).<pub-id pub-id-type="pmid">29220095</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR50"><label>50.</label><citation-alternatives><element-citation id="ec-CR50" publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>S</given-names></name><name><surname>Acs</surname><given-names>B</given-names></name><name><surname>Lippert</surname><given-names>M</given-names></name><name><surname>Hartman</surname><given-names>J</given-names></name></person-group><article-title>Prognostic potential of automated Ki67 evaluation in breast cancer: Different hot spot definitions versus true global score</article-title><source>Breast Cancer Res. Treat.</source><year>2020</year><volume>183</volume><fpage>161</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1007/s10549-020-05752-w</pub-id><pub-id pub-id-type="pmid">32572716</pub-id>
</element-citation><mixed-citation id="mc-CR50" publication-type="journal">Robertson, S., Acs, B., Lippert, M. &#x00026; Hartman, J. Prognostic potential of automated Ki67 evaluation in breast cancer: Different hot spot definitions versus true global score. <italic>Breast Cancer Res. Treat.</italic><bold>183</bold>, 161&#x02013;175. 10.1007/s10549-020-05752-w (2020).<pub-id pub-id-type="pmid">32572716</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR51"><label>51.</label><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name><surname>Paik</surname><given-names>S</given-names></name><etal/></person-group><article-title>Systematic evaluation of scoring methods for Ki67 as a surrogate for 21-gene recurrence score</article-title><source>Npj Breast Cancer</source><year>2021</year><volume>7</volume><fpage>13</fpage><pub-id pub-id-type="doi">10.1038/s41523-021-00221-z</pub-id><pub-id pub-id-type="pmid">33579950</pub-id>
</element-citation><mixed-citation id="mc-CR51" publication-type="journal">Paik, S. et al. Systematic evaluation of scoring methods for Ki67 as a surrogate for 21-gene recurrence score. <italic>Npj Breast Cancer</italic>. <bold>7</bold>, 13. 10.1038/s41523-021-00221-z (2021).<pub-id pub-id-type="pmid">33579950</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Swiderska, Z. et al. Comparison of the manual, semiautomatic, and automatic selection and leveling of hot spots in whole slide images for Ki-67 quantification in meningiomas. <italic>Anal. Cell Pathol. (Amst)</italic><bold>2015</bold>, 498746. 10.1155/2015/498746 (2015).</mixed-citation></ref><ref id="CR53"><label>53.</label><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name><surname>Zwager</surname><given-names>MC</given-names></name><etal/></person-group><article-title>Advancing Ki67 hotspot detection in breast cancer: A comparative analysis of automated digital image analysis algorithms</article-title><source>Histopathology</source><year>2025</year><volume>86</volume><fpage>204</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1111/his.15294</pub-id><pub-id pub-id-type="pmid">39104219</pub-id>
</element-citation><mixed-citation id="mc-CR53" publication-type="journal">Zwager, M. C. et al. Advancing Ki67 hotspot detection in breast cancer: A comparative analysis of automated digital image analysis algorithms. <italic>Histopathology</italic><bold>86</bold>, 204&#x02013;213. 10.1111/his.15294 (2025).<pub-id pub-id-type="pmid">39104219</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR54"><label>54.</label><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M</given-names></name><etal/></person-group><article-title>Digital image analysis of Ki67 heterogeneity improves the diagnosis and prognosis of gastroenteropancreatic neuroendocrine neoplasms</article-title><source>Mod. Pathology: Official J. United States Can. Acad. Pathol. Inc</source><year>2023</year><volume>36</volume><fpage>100017</fpage><pub-id pub-id-type="doi">10.1016/j.modpat.2022.100017</pub-id></element-citation><mixed-citation id="mc-CR54" publication-type="journal">Zhang, M. et al. Digital image analysis of Ki67 heterogeneity improves the diagnosis and prognosis of gastroenteropancreatic neuroendocrine neoplasms. <italic>Mod. Pathology: Official J. United States Can. Acad. Pathol. Inc</italic>. <bold>36</bold>, 100017. 10.1016/j.modpat.2022.100017 (2023).</mixed-citation></citation-alternatives></ref></ref-list></back></article>