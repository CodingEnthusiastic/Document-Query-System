<p xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" id="Par25">A convolutional neural network was established on Aiforia (Aiforia Technologies Oyj, Helsinki, Finland), a cloud-based ML platform. The use of this ML-based platform was chosen to leverage state-of-the-art technology. It also offers excellent customer support and a user-friendly interface, making it easy to experiment with and implement the ML analysis. For our study, the convolutional neural network consisted of two neural networks. The first neural network segmented tumor areas, and the second network detected Ki67 positive and negative tumor cells within the segmented tumor areas (Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>c). Annotations and analyses, in here also, were performed by the first author (MSc in biomedicine) under the supervision of an experienced gastrointestinal pathologist (SL). The output included the number of detected tumor cells and their center coordinates. The training/validation dataset (<italic>n</italic>&#8201;=&#8201;29) included 6&#8197;072 manually annotated tumor areas and 13&#8197;030 labeled Ki67 positive/negative tumor cells for training. The AI model was trained from scratch and initialized with random values. The mini batch size was 20 by default and no cross-validation was used. The training dataset was digitally augmented using random scaling of &#8722;&#160;20 to 20%, 0 to 10% aspect ratio change, 0 to 10% shear angle, &#8722; 20 to 20% brightness and &#8722;&#8201;10 to 10% contrast change, 0&#8211;1% white balance change, and flipping both vertically and horizontally (Supplementary Table <xref rid="MOESM2" ref-type="media">S2</xref>). The number of training iterations was set to 30,000. The fine-tuning of hyperparameters was conducted in collaboration with Aiforia&#8217;s specialists, leveraging their expertise to optimize the model for accuracy and efficiency. The performance of our trained model was evaluated on previously unseen regions from the training/validation dataset and further tested on the independent test dataset, using statistical measures including precision, sensitivity, and the F-score, in addition to visual inspection.</p>